{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment 1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "gnDXPAevb15x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d15d66a4-58e1-4fe7-8f6d-14f866e70843"
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import math\n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/gdrive')\n",
        "\n",
        "TRAIN_START = 101\n",
        "TRAIN_END = 1000\n",
        "CLASS_SIZE = 4\n",
        "BASE = 3\n",
        "NUM_EPOCHS = 1000\n",
        "\n",
        "\n",
        "\n",
        "def fizz_buzz_logic(n):\n",
        "    for i in range(1, n+1):\n",
        "        if i % 15 == 0:\n",
        "            print(\"FizzBuzz\")\n",
        "        elif i % 3 == 0:\n",
        "            print(\"Fizz\")\n",
        "        elif i % 5 == 0:\n",
        "            print(\"Buzz\")\n",
        "        else:\n",
        "            print(i)\n",
        "\n",
        "\n",
        "def fizz_buzz_out(train_inp):\n",
        "    train_out = np.ndarray((len(train_inp), 4))\n",
        "    ind = 0\n",
        "    for i in train_inp:\n",
        "        if i % 15 == 0:\n",
        "            out = [1, 0, 0, 0]\n",
        "        elif i % 3 == 0:\n",
        "            out = [0, 1, 0, 0]\n",
        "        elif i % 5 == 0:\n",
        "            out = [0, 0, 1, 0]\n",
        "        else:\n",
        "            out = [0, 0, 0, 1]\n",
        "        train_out[ind] = out\n",
        "        ind += 1\n",
        "    return train_out\n",
        "\n",
        "\n",
        "def init_weights(shape):\n",
        "    return tf.Variable(tf.random_normal(shape, stddev=0.01))\n",
        "\n",
        "\n",
        "def model(X, w_h, w_o):\n",
        "    h = tf.nn.relu(tf.matmul(X, w_h))\n",
        "    return tf.matmul(h, w_o)\n",
        "\n",
        "\n",
        "def get_randomized_weights():\n",
        "    w_h = init_weights([900, NUM_HIDDEN])\n",
        "    w_o = init_weights([NUM_HIDDEN, 1])\n",
        "    return w_h, w_o\n",
        "\n",
        "\n",
        "def train_model(py_x, Y):\n",
        "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(py_x, Y))\n",
        "    train_op = tf.train.GradientDescentOptimizer(0.05).minimize(cost)\n",
        "    return train_op\n",
        "\n",
        "def normalize_data(train_data, test_data):\n",
        "    train_data, test_data = train_data / (CLASS_SIZE - 1), test_data / (CLASS_SIZE - 1)\n",
        "    return train_data, test_data\n",
        "\n",
        "def structurize_data(data, size):\n",
        "    str_data = np.ndarray((len(data), size), dtype='float')\n",
        "    for i in range(len(data)):\n",
        "        for j in range(size):\n",
        "            x = data[i]%(BASE ** (j+1))\n",
        "            str_data[i][j] = (int(x/(BASE ** j)))\n",
        "    return str_data\n",
        "\n",
        "def base_len(size, base):\n",
        "    i = 0\n",
        "    while size != 0:\n",
        "        i = i+1\n",
        "        size = int(size / base)\n",
        "    return i\n",
        "\n",
        "def get_label(label, val):\n",
        "    if label == 0:\n",
        "        return \"FizzBuzz\"\n",
        "    if label == 1:\n",
        "        return \"Fizz\"\n",
        "    if label == 2:\n",
        "        return \"Buzz\"\n",
        "    if label == 3:\n",
        "        return str(val)\n",
        "\n",
        "def fizz_buzz_NN():\n",
        "    size = base_len(TRAIN_END, BASE) + 1\n",
        "    inp = np.array(range(TRAIN_START, TRAIN_END + 1), dtype='float')\n",
        "    tst = np.array(range(1, TRAIN_START), dtype='float')\n",
        "    train_inp = structurize_data(inp, size) #inp\n",
        "    train_out = fizz_buzz_out(inp)\n",
        "    test_inp = structurize_data(tst, size) #tst\n",
        "    test_out = fizz_buzz_out(tst)\n",
        "    model = tf.keras.models.Sequential([\n",
        "        tf.keras.layers.Dense(512, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(1024, activation='relu'),\n",
        "        tf.keras.layers.Dropout(0.2),\n",
        "        tf.keras.layers.Dense(CLASS_SIZE, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(optimizer='RMSprop',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "    # print(model.get_weights())\n",
        "    model.fit(train_inp, train_out, epochs=NUM_EPOCHS)\n",
        "    model.save(\"fizz_buzz_model.h5\")\n",
        "    model.evaluate(test_inp,  test_out, verbose=2)\n",
        "    predictions = model.predict_classes(test_inp)\n",
        "    print(predictions[0])\n",
        "    for i in range(1, TRAIN_START):\n",
        "        print(str(i) + \" \" + get_label(predictions[i-1], i))\n",
        "\n",
        "def main():\n",
        "    fizz_buzz_NN()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 900 samples\n",
            "Epoch 1/1000\n",
            "900/900 [==============================] - 1s 695us/sample - loss: 0.7329 - acc: 0.7633\n",
            "Epoch 2/1000\n",
            "900/900 [==============================] - 0s 398us/sample - loss: 0.5753 - acc: 0.7911\n",
            "Epoch 3/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.5430 - acc: 0.7911\n",
            "Epoch 4/1000\n",
            "900/900 [==============================] - 0s 392us/sample - loss: 0.5378 - acc: 0.7989\n",
            "Epoch 5/1000\n",
            "900/900 [==============================] - 0s 419us/sample - loss: 0.5255 - acc: 0.8000\n",
            "Epoch 6/1000\n",
            "900/900 [==============================] - 0s 400us/sample - loss: 0.5348 - acc: 0.8022\n",
            "Epoch 7/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.5263 - acc: 0.8000\n",
            "Epoch 8/1000\n",
            "900/900 [==============================] - 0s 379us/sample - loss: 0.5202 - acc: 0.8000\n",
            "Epoch 9/1000\n",
            "900/900 [==============================] - 0s 371us/sample - loss: 0.5171 - acc: 0.8000\n",
            "Epoch 10/1000\n",
            "900/900 [==============================] - 0s 376us/sample - loss: 0.5197 - acc: 0.8000\n",
            "Epoch 11/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.5234 - acc: 0.8000\n",
            "Epoch 12/1000\n",
            "900/900 [==============================] - 0s 374us/sample - loss: 0.5098 - acc: 0.7989\n",
            "Epoch 13/1000\n",
            "900/900 [==============================] - 0s 383us/sample - loss: 0.5077 - acc: 0.8000\n",
            "Epoch 14/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.5076 - acc: 0.8000\n",
            "Epoch 15/1000\n",
            "900/900 [==============================] - 0s 411us/sample - loss: 0.5100 - acc: 0.8011\n",
            "Epoch 16/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.5002 - acc: 0.7967\n",
            "Epoch 17/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.5050 - acc: 0.8000\n",
            "Epoch 18/1000\n",
            "900/900 [==============================] - 0s 409us/sample - loss: 0.4929 - acc: 0.8022\n",
            "Epoch 19/1000\n",
            "900/900 [==============================] - 0s 436us/sample - loss: 0.5005 - acc: 0.8000\n",
            "Epoch 20/1000\n",
            "900/900 [==============================] - 0s 403us/sample - loss: 0.4838 - acc: 0.8000\n",
            "Epoch 21/1000\n",
            "900/900 [==============================] - 0s 410us/sample - loss: 0.4927 - acc: 0.8000\n",
            "Epoch 22/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.4802 - acc: 0.8056\n",
            "Epoch 23/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.4745 - acc: 0.8033\n",
            "Epoch 24/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.4666 - acc: 0.8022\n",
            "Epoch 25/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.4556 - acc: 0.8100\n",
            "Epoch 26/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.4485 - acc: 0.8133\n",
            "Epoch 27/1000\n",
            "900/900 [==============================] - 0s 387us/sample - loss: 0.4452 - acc: 0.8244\n",
            "Epoch 28/1000\n",
            "900/900 [==============================] - 0s 401us/sample - loss: 0.4329 - acc: 0.8244\n",
            "Epoch 29/1000\n",
            "900/900 [==============================] - 0s 423us/sample - loss: 0.4330 - acc: 0.8244\n",
            "Epoch 30/1000\n",
            "900/900 [==============================] - 0s 414us/sample - loss: 0.4167 - acc: 0.8344\n",
            "Epoch 31/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.4076 - acc: 0.8389\n",
            "Epoch 32/1000\n",
            "900/900 [==============================] - 0s 412us/sample - loss: 0.4031 - acc: 0.8400\n",
            "Epoch 33/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.3840 - acc: 0.8500\n",
            "Epoch 34/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.3792 - acc: 0.8467\n",
            "Epoch 35/1000\n",
            "900/900 [==============================] - 0s 407us/sample - loss: 0.3587 - acc: 0.8600\n",
            "Epoch 36/1000\n",
            "900/900 [==============================] - 0s 398us/sample - loss: 0.3467 - acc: 0.8567\n",
            "Epoch 37/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.3395 - acc: 0.8722\n",
            "Epoch 38/1000\n",
            "900/900 [==============================] - 0s 409us/sample - loss: 0.3445 - acc: 0.8544\n",
            "Epoch 39/1000\n",
            "900/900 [==============================] - 0s 418us/sample - loss: 0.3263 - acc: 0.8789\n",
            "Epoch 40/1000\n",
            "900/900 [==============================] - 0s 407us/sample - loss: 0.3172 - acc: 0.8800\n",
            "Epoch 41/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.3044 - acc: 0.8856\n",
            "Epoch 42/1000\n",
            "900/900 [==============================] - 0s 415us/sample - loss: 0.3104 - acc: 0.8711\n",
            "Epoch 43/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.2846 - acc: 0.8944\n",
            "Epoch 44/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.2778 - acc: 0.8978\n",
            "Epoch 45/1000\n",
            "900/900 [==============================] - 0s 409us/sample - loss: 0.2720 - acc: 0.8878\n",
            "Epoch 46/1000\n",
            "900/900 [==============================] - 0s 425us/sample - loss: 0.2591 - acc: 0.9089\n",
            "Epoch 47/1000\n",
            "900/900 [==============================] - 0s 432us/sample - loss: 0.2660 - acc: 0.9022\n",
            "Epoch 48/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.2708 - acc: 0.9056\n",
            "Epoch 49/1000\n",
            "900/900 [==============================] - 0s 385us/sample - loss: 0.2334 - acc: 0.9122\n",
            "Epoch 50/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.2366 - acc: 0.9189\n",
            "Epoch 51/1000\n",
            "900/900 [==============================] - 0s 375us/sample - loss: 0.2136 - acc: 0.9167\n",
            "Epoch 52/1000\n",
            "900/900 [==============================] - 0s 399us/sample - loss: 0.2323 - acc: 0.9078\n",
            "Epoch 53/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.2283 - acc: 0.9289\n",
            "Epoch 54/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.2093 - acc: 0.9267\n",
            "Epoch 55/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.2044 - acc: 0.9311\n",
            "Epoch 56/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.1797 - acc: 0.9333\n",
            "Epoch 57/1000\n",
            "900/900 [==============================] - 0s 378us/sample - loss: 0.1723 - acc: 0.9344\n",
            "Epoch 58/1000\n",
            "900/900 [==============================] - 0s 394us/sample - loss: 0.1876 - acc: 0.9322\n",
            "Epoch 59/1000\n",
            "900/900 [==============================] - 0s 376us/sample - loss: 0.1975 - acc: 0.9344\n",
            "Epoch 60/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.1663 - acc: 0.9489\n",
            "Epoch 61/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.1868 - acc: 0.9311\n",
            "Epoch 62/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.1624 - acc: 0.9356\n",
            "Epoch 63/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.1564 - acc: 0.9511\n",
            "Epoch 64/1000\n",
            "900/900 [==============================] - 0s 383us/sample - loss: 0.1651 - acc: 0.9467\n",
            "Epoch 65/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.1597 - acc: 0.9400\n",
            "Epoch 66/1000\n",
            "900/900 [==============================] - 0s 392us/sample - loss: 0.1459 - acc: 0.9522\n",
            "Epoch 67/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.1436 - acc: 0.9522\n",
            "Epoch 68/1000\n",
            "900/900 [==============================] - 0s 372us/sample - loss: 0.1267 - acc: 0.9556\n",
            "Epoch 69/1000\n",
            "900/900 [==============================] - 0s 411us/sample - loss: 0.1493 - acc: 0.9511\n",
            "Epoch 70/1000\n",
            "900/900 [==============================] - 0s 394us/sample - loss: 0.1418 - acc: 0.9589\n",
            "Epoch 71/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.1406 - acc: 0.9478\n",
            "Epoch 72/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.1217 - acc: 0.9578\n",
            "Epoch 73/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.1461 - acc: 0.9500\n",
            "Epoch 74/1000\n",
            "900/900 [==============================] - 0s 401us/sample - loss: 0.1329 - acc: 0.9533\n",
            "Epoch 75/1000\n",
            "900/900 [==============================] - 0s 432us/sample - loss: 0.1232 - acc: 0.9556\n",
            "Epoch 76/1000\n",
            "900/900 [==============================] - 0s 433us/sample - loss: 0.1190 - acc: 0.9633\n",
            "Epoch 77/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.1239 - acc: 0.9567\n",
            "Epoch 78/1000\n",
            "900/900 [==============================] - 0s 407us/sample - loss: 0.1064 - acc: 0.9656\n",
            "Epoch 79/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.1179 - acc: 0.9567\n",
            "Epoch 80/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.1234 - acc: 0.9622\n",
            "Epoch 81/1000\n",
            "900/900 [==============================] - 0s 392us/sample - loss: 0.1079 - acc: 0.9556\n",
            "Epoch 82/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.1037 - acc: 0.9633\n",
            "Epoch 83/1000\n",
            "900/900 [==============================] - 0s 381us/sample - loss: 0.0881 - acc: 0.9656\n",
            "Epoch 84/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.0969 - acc: 0.9644\n",
            "Epoch 85/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0938 - acc: 0.9667\n",
            "Epoch 86/1000\n",
            "900/900 [==============================] - 0s 378us/sample - loss: 0.1053 - acc: 0.9667\n",
            "Epoch 87/1000\n",
            "900/900 [==============================] - 0s 401us/sample - loss: 0.1088 - acc: 0.9722\n",
            "Epoch 88/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0849 - acc: 0.9711\n",
            "Epoch 89/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.0918 - acc: 0.9600\n",
            "Epoch 90/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.0932 - acc: 0.9667\n",
            "Epoch 91/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.0790 - acc: 0.9767\n",
            "Epoch 92/1000\n",
            "900/900 [==============================] - 0s 385us/sample - loss: 0.1173 - acc: 0.9522\n",
            "Epoch 93/1000\n",
            "900/900 [==============================] - 0s 401us/sample - loss: 0.0831 - acc: 0.9811\n",
            "Epoch 94/1000\n",
            "900/900 [==============================] - 0s 407us/sample - loss: 0.1002 - acc: 0.9644\n",
            "Epoch 95/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.0554 - acc: 0.9822\n",
            "Epoch 96/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.0802 - acc: 0.9700\n",
            "Epoch 97/1000\n",
            "900/900 [==============================] - 0s 400us/sample - loss: 0.0752 - acc: 0.9722\n",
            "Epoch 98/1000\n",
            "900/900 [==============================] - 0s 420us/sample - loss: 0.0722 - acc: 0.9722\n",
            "Epoch 99/1000\n",
            "900/900 [==============================] - 0s 380us/sample - loss: 0.0709 - acc: 0.9767\n",
            "Epoch 100/1000\n",
            "900/900 [==============================] - 0s 389us/sample - loss: 0.0600 - acc: 0.9767\n",
            "Epoch 101/1000\n",
            "900/900 [==============================] - 0s 383us/sample - loss: 0.0812 - acc: 0.9744\n",
            "Epoch 102/1000\n",
            "900/900 [==============================] - 0s 400us/sample - loss: 0.0638 - acc: 0.9800\n",
            "Epoch 103/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0663 - acc: 0.9767\n",
            "Epoch 104/1000\n",
            "900/900 [==============================] - 0s 377us/sample - loss: 0.0555 - acc: 0.9811\n",
            "Epoch 105/1000\n",
            "900/900 [==============================] - 0s 419us/sample - loss: 0.0688 - acc: 0.9822\n",
            "Epoch 106/1000\n",
            "900/900 [==============================] - 0s 382us/sample - loss: 0.0700 - acc: 0.9711\n",
            "Epoch 107/1000\n",
            "900/900 [==============================] - 0s 383us/sample - loss: 0.0559 - acc: 0.9833\n",
            "Epoch 108/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0698 - acc: 0.9733\n",
            "Epoch 109/1000\n",
            "900/900 [==============================] - 0s 377us/sample - loss: 0.0585 - acc: 0.9833\n",
            "Epoch 110/1000\n",
            "900/900 [==============================] - 0s 397us/sample - loss: 0.0655 - acc: 0.9778\n",
            "Epoch 111/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.0690 - acc: 0.9733\n",
            "Epoch 112/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.0423 - acc: 0.9900\n",
            "Epoch 113/1000\n",
            "900/900 [==============================] - 0s 382us/sample - loss: 0.0622 - acc: 0.9756\n",
            "Epoch 114/1000\n",
            "900/900 [==============================] - 0s 398us/sample - loss: 0.0415 - acc: 0.9833\n",
            "Epoch 115/1000\n",
            "900/900 [==============================] - 0s 394us/sample - loss: 0.0613 - acc: 0.9767\n",
            "Epoch 116/1000\n",
            "900/900 [==============================] - 0s 421us/sample - loss: 0.0451 - acc: 0.9867\n",
            "Epoch 117/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.0482 - acc: 0.9833\n",
            "Epoch 118/1000\n",
            "900/900 [==============================] - 0s 416us/sample - loss: 0.0562 - acc: 0.9833\n",
            "Epoch 119/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.0368 - acc: 0.9911\n",
            "Epoch 120/1000\n",
            "900/900 [==============================] - 0s 414us/sample - loss: 0.0462 - acc: 0.9867\n",
            "Epoch 121/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.0561 - acc: 0.9811\n",
            "Epoch 122/1000\n",
            "900/900 [==============================] - 0s 379us/sample - loss: 0.0492 - acc: 0.9867\n",
            "Epoch 123/1000\n",
            "900/900 [==============================] - 0s 378us/sample - loss: 0.0631 - acc: 0.9789\n",
            "Epoch 124/1000\n",
            "900/900 [==============================] - 0s 398us/sample - loss: 0.0286 - acc: 0.9933\n",
            "Epoch 125/1000\n",
            "900/900 [==============================] - 0s 381us/sample - loss: 0.0520 - acc: 0.9800\n",
            "Epoch 126/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.0538 - acc: 0.9822\n",
            "Epoch 127/1000\n",
            "900/900 [==============================] - 0s 375us/sample - loss: 0.0348 - acc: 0.9889\n",
            "Epoch 128/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.0356 - acc: 0.9856\n",
            "Epoch 129/1000\n",
            "900/900 [==============================] - 0s 401us/sample - loss: 0.0283 - acc: 0.9911\n",
            "Epoch 130/1000\n",
            "900/900 [==============================] - 0s 409us/sample - loss: 0.0330 - acc: 0.9900\n",
            "Epoch 131/1000\n",
            "900/900 [==============================] - 0s 407us/sample - loss: 0.0621 - acc: 0.9800\n",
            "Epoch 132/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.0342 - acc: 0.9867\n",
            "Epoch 133/1000\n",
            "900/900 [==============================] - 0s 397us/sample - loss: 0.0467 - acc: 0.9889\n",
            "Epoch 134/1000\n",
            "900/900 [==============================] - 0s 418us/sample - loss: 0.0449 - acc: 0.9844\n",
            "Epoch 135/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.0461 - acc: 0.9844\n",
            "Epoch 136/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.0404 - acc: 0.9844\n",
            "Epoch 137/1000\n",
            "900/900 [==============================] - 0s 398us/sample - loss: 0.0374 - acc: 0.9878\n",
            "Epoch 138/1000\n",
            "900/900 [==============================] - 0s 413us/sample - loss: 0.0309 - acc: 0.9900\n",
            "Epoch 139/1000\n",
            "900/900 [==============================] - 0s 403us/sample - loss: 0.0419 - acc: 0.9844\n",
            "Epoch 140/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.0297 - acc: 0.9933\n",
            "Epoch 141/1000\n",
            "900/900 [==============================] - 0s 397us/sample - loss: 0.0289 - acc: 0.9922\n",
            "Epoch 142/1000\n",
            "900/900 [==============================] - 0s 368us/sample - loss: 0.0444 - acc: 0.9889\n",
            "Epoch 143/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0401 - acc: 0.9889\n",
            "Epoch 144/1000\n",
            "900/900 [==============================] - 0s 387us/sample - loss: 0.0318 - acc: 0.9900\n",
            "Epoch 145/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.0309 - acc: 0.9900\n",
            "Epoch 146/1000\n",
            "900/900 [==============================] - 0s 403us/sample - loss: 0.0361 - acc: 0.9900\n",
            "Epoch 147/1000\n",
            "900/900 [==============================] - 0s 374us/sample - loss: 0.0312 - acc: 0.9889\n",
            "Epoch 148/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0451 - acc: 0.9900\n",
            "Epoch 149/1000\n",
            "900/900 [==============================] - 0s 387us/sample - loss: 0.0297 - acc: 0.9889\n",
            "Epoch 150/1000\n",
            "900/900 [==============================] - 0s 384us/sample - loss: 0.0224 - acc: 0.9944\n",
            "Epoch 151/1000\n",
            "900/900 [==============================] - 0s 376us/sample - loss: 0.0353 - acc: 0.9889\n",
            "Epoch 152/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.0382 - acc: 0.9867\n",
            "Epoch 153/1000\n",
            "900/900 [==============================] - 0s 377us/sample - loss: 0.0366 - acc: 0.9878\n",
            "Epoch 154/1000\n",
            "900/900 [==============================] - 0s 380us/sample - loss: 0.0239 - acc: 0.9956\n",
            "Epoch 155/1000\n",
            "900/900 [==============================] - 0s 376us/sample - loss: 0.0199 - acc: 0.9956\n",
            "Epoch 156/1000\n",
            "900/900 [==============================] - 0s 380us/sample - loss: 0.0375 - acc: 0.9911\n",
            "Epoch 157/1000\n",
            "900/900 [==============================] - 0s 371us/sample - loss: 0.0259 - acc: 0.9889\n",
            "Epoch 158/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.0323 - acc: 0.9889\n",
            "Epoch 159/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0280 - acc: 0.9889\n",
            "Epoch 160/1000\n",
            "900/900 [==============================] - 0s 411us/sample - loss: 0.0266 - acc: 0.9856\n",
            "Epoch 161/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.0242 - acc: 0.9867\n",
            "Epoch 162/1000\n",
            "900/900 [==============================] - 0s 419us/sample - loss: 0.0377 - acc: 0.9867\n",
            "Epoch 163/1000\n",
            "900/900 [==============================] - 0s 434us/sample - loss: 0.0356 - acc: 0.9889\n",
            "Epoch 164/1000\n",
            "900/900 [==============================] - 0s 417us/sample - loss: 0.0228 - acc: 0.9933\n",
            "Epoch 165/1000\n",
            "900/900 [==============================] - 0s 394us/sample - loss: 0.0293 - acc: 0.9922\n",
            "Epoch 166/1000\n",
            "900/900 [==============================] - 0s 385us/sample - loss: 0.0119 - acc: 0.9978\n",
            "Epoch 167/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.0259 - acc: 0.9922\n",
            "Epoch 168/1000\n",
            "900/900 [==============================] - 0s 383us/sample - loss: 0.0307 - acc: 0.9900\n",
            "Epoch 169/1000\n",
            "900/900 [==============================] - 0s 399us/sample - loss: 0.0595 - acc: 0.9811\n",
            "Epoch 170/1000\n",
            "900/900 [==============================] - 0s 409us/sample - loss: 0.0321 - acc: 0.9889\n",
            "Epoch 171/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.0203 - acc: 0.9933\n",
            "Epoch 172/1000\n",
            "900/900 [==============================] - 0s 393us/sample - loss: 0.0265 - acc: 0.9867\n",
            "Epoch 173/1000\n",
            "900/900 [==============================] - 0s 376us/sample - loss: 0.0178 - acc: 0.9933\n",
            "Epoch 174/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0248 - acc: 0.9956\n",
            "Epoch 175/1000\n",
            "900/900 [==============================] - 0s 381us/sample - loss: 0.0242 - acc: 0.9911\n",
            "Epoch 176/1000\n",
            "900/900 [==============================] - 0s 387us/sample - loss: 0.0319 - acc: 0.9889\n",
            "Epoch 177/1000\n",
            "900/900 [==============================] - 0s 379us/sample - loss: 0.0339 - acc: 0.9889\n",
            "Epoch 178/1000\n",
            "900/900 [==============================] - 0s 406us/sample - loss: 0.0289 - acc: 0.9933\n",
            "Epoch 179/1000\n",
            "900/900 [==============================] - 0s 392us/sample - loss: 0.0186 - acc: 0.9933\n",
            "Epoch 180/1000\n",
            "900/900 [==============================] - 0s 397us/sample - loss: 0.0328 - acc: 0.9867\n",
            "Epoch 181/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0244 - acc: 0.9889\n",
            "Epoch 182/1000\n",
            "900/900 [==============================] - 0s 384us/sample - loss: 0.0310 - acc: 0.9922\n",
            "Epoch 183/1000\n",
            "900/900 [==============================] - 0s 375us/sample - loss: 0.0250 - acc: 0.9911\n",
            "Epoch 184/1000\n",
            "900/900 [==============================] - 0s 378us/sample - loss: 0.0289 - acc: 0.9944\n",
            "Epoch 185/1000\n",
            "900/900 [==============================] - 0s 366us/sample - loss: 0.0267 - acc: 0.9911\n",
            "Epoch 186/1000\n",
            "900/900 [==============================] - 0s 370us/sample - loss: 0.0264 - acc: 0.9922\n",
            "Epoch 187/1000\n",
            "900/900 [==============================] - 0s 374us/sample - loss: 0.0171 - acc: 0.9967\n",
            "Epoch 188/1000\n",
            "900/900 [==============================] - 0s 371us/sample - loss: 0.0414 - acc: 0.9844\n",
            "Epoch 189/1000\n",
            "900/900 [==============================] - 0s 386us/sample - loss: 0.0161 - acc: 0.9956\n",
            "Epoch 190/1000\n",
            "900/900 [==============================] - 0s 367us/sample - loss: 0.0159 - acc: 0.9922\n",
            "Epoch 191/1000\n",
            "900/900 [==============================] - 0s 370us/sample - loss: 0.0213 - acc: 0.9944\n",
            "Epoch 192/1000\n",
            "900/900 [==============================] - 0s 370us/sample - loss: 0.0336 - acc: 0.9900\n",
            "Epoch 193/1000\n",
            "900/900 [==============================] - 0s 390us/sample - loss: 0.0159 - acc: 0.9956\n",
            "Epoch 194/1000\n",
            "900/900 [==============================] - 0s 359us/sample - loss: 0.0241 - acc: 0.9944\n",
            "Epoch 195/1000\n",
            "900/900 [==============================] - 0s 366us/sample - loss: 0.0218 - acc: 0.9944\n",
            "Epoch 196/1000\n",
            "900/900 [==============================] - 0s 381us/sample - loss: 0.0222 - acc: 0.9911\n",
            "Epoch 197/1000\n",
            "900/900 [==============================] - 0s 385us/sample - loss: 0.0490 - acc: 0.9867\n",
            "Epoch 198/1000\n",
            "900/900 [==============================] - 0s 396us/sample - loss: 0.0262 - acc: 0.9922\n",
            "Epoch 199/1000\n",
            "900/900 [==============================] - 0s 384us/sample - loss: 0.0191 - acc: 0.9956\n",
            "Epoch 200/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.0113 - acc: 0.9956\n",
            "Epoch 201/1000\n",
            "900/900 [==============================] - 0s 399us/sample - loss: 0.0284 - acc: 0.9911\n",
            "Epoch 202/1000\n",
            "900/900 [==============================] - 0s 404us/sample - loss: 0.0159 - acc: 0.9956\n",
            "Epoch 203/1000\n",
            "900/900 [==============================] - 0s 412us/sample - loss: 0.0111 - acc: 0.9978\n",
            "Epoch 204/1000\n",
            "900/900 [==============================] - 0s 400us/sample - loss: 0.0244 - acc: 0.9911\n",
            "Epoch 205/1000\n",
            "900/900 [==============================] - 0s 385us/sample - loss: 0.0242 - acc: 0.9922\n",
            "Epoch 206/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0268 - acc: 0.9889\n",
            "Epoch 207/1000\n",
            "900/900 [==============================] - 0s 391us/sample - loss: 0.0190 - acc: 0.9933\n",
            "Epoch 208/1000\n",
            "900/900 [==============================] - 0s 403us/sample - loss: 0.0096 - acc: 0.9967\n",
            "Epoch 209/1000\n",
            "900/900 [==============================] - 0s 381us/sample - loss: 0.0094 - acc: 0.9967\n",
            "Epoch 210/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.0228 - acc: 0.9944\n",
            "Epoch 211/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.0053 - acc: 0.9989\n",
            "Epoch 212/1000\n",
            "900/900 [==============================] - 0s 377us/sample - loss: 0.0214 - acc: 0.9911\n",
            "Epoch 213/1000\n",
            "900/900 [==============================] - 0s 408us/sample - loss: 0.0377 - acc: 0.9944\n",
            "Epoch 214/1000\n",
            "900/900 [==============================] - 0s 386us/sample - loss: 0.0055 - acc: 0.9989\n",
            "Epoch 215/1000\n",
            "900/900 [==============================] - 0s 395us/sample - loss: 0.0069 - acc: 0.9978\n",
            "Epoch 216/1000\n",
            "900/900 [==============================] - 0s 397us/sample - loss: 0.0130 - acc: 0.9967\n",
            "Epoch 217/1000\n",
            "900/900 [==============================] - 0s 386us/sample - loss: 0.0331 - acc: 0.9900\n",
            "Epoch 218/1000\n",
            "900/900 [==============================] - 0s 402us/sample - loss: 0.0380 - acc: 0.9878\n",
            "Epoch 219/1000\n",
            "900/900 [==============================] - 0s 420us/sample - loss: 0.0255 - acc: 0.9900\n",
            "Epoch 220/1000\n",
            "900/900 [==============================] - 0s 405us/sample - loss: 0.0166 - acc: 0.9956\n",
            "Epoch 221/1000\n",
            "900/900 [==============================] - 0s 400us/sample - loss: 0.0187 - acc: 0.9922\n",
            "Epoch 222/1000\n",
            "900/900 [==============================] - 0s 420us/sample - loss: 0.0393 - acc: 0.9911\n",
            "Epoch 223/1000\n",
            "900/900 [==============================] - 0s 388us/sample - loss: 0.0171 - acc: 0.9922\n",
            "Epoch 224/1000\n",
            "448/900 [=============>................] - ETA: 0s - loss: 0.0211 - acc: 0.9933"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}